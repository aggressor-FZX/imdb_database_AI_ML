{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMDB exploratory data analysis to isolate factors which contribute most to movie profitability or popularity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#need to make a table that has the top 33% of movies by popularity, with ratings over 7.0, and actors/actresses in the cast\n",
    "#need to include the actor/actress name, movie name, rating, profit, and popularity\n",
    "#adjust as needed\n",
    "cte_mega_string = \"\"\"\n",
    "\n",
    "WITH FilteredRatings AS (\n",
    "    SELECT tconst, averageRating, numVotes\n",
    "    FROM dbo.ratings\n",
    "    WHERE averageRating > 4.0\n",
    "),\n",
    "--break list by popularity into n-tile\n",
    "FilteredPopularity AS (\n",
    "    Select\n",
    "        imdb_id,\n",
    "        popularity,\n",
    "        genres,\n",
    "        overview,\n",
    "        ProductionCompanies,\n",
    "        NTILE(1) OVER (ORDER BY popularity DESC) AS popularity_percentile \n",
    "    from dbo.meta\n",
    "),\n",
    "FilteredBasics AS (\n",
    "    SELECT tconst, primaryTitle, startYear, runtimeMinutes\n",
    "    FROM dbo.basics\n",
    "    WHERE startYear >= 2010\n",
    "),\n",
    "Budget AS (\n",
    "    SELECT \n",
    "        imdb_id,\n",
    "        budget,\n",
    "        (revenue - budget) AS profit,\n",
    "    FROM dbo.meta\n",
    ")\n",
    "SELECT DISTINCT\n",
    "    cast.tconst, -- movie number unique id\n",
    "    base.primaryTitle, --movie name\n",
    "    cast.category,\n",
    "    rates.averageRating, -- ratings\n",
    "    nam.primaryName AS actor_name,\n",
    "    budget.budget,\n",
    "    budget.profit,\n",
    "    pop.popularity,\n",
    "    pop.genres,\n",
    "    pop.ProductionCompanies,\n",
    "    pop.overview\n",
    "\n",
    "FROM dbo.principals AS cast\n",
    "JOIN FilteredBasics AS base ON base.tconst = cast.tconst\n",
    "JOIN FilteredRatings AS rates ON rates.tconst = cast.tconst\n",
    "JOIN budget on budget.imdb_id = cast.tconst\n",
    "JOIN dbo.name AS nam ON nam.nconst = cast.nconst\n",
    "JOIN FilteredPopularity AS pop ON pop.imdb_id = cast.tconst\n",
    "WHERE cast.category IN ('actor', 'actress')\n",
    "    AND pop.popularity_percentile = 1\n",
    "ORDER BY pop.popularity DESC;\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ProgrammingError",
     "evalue": "(pyodbc.ProgrammingError) ('42000', \"[42000] [Microsoft][ODBC Driver 17 for SQL Server][SQL Server]Incorrect syntax near the keyword 'FROM'. (156) (SQLExecDirectW)\")\n[SQL: \n\nWITH FilteredRatings AS (\n    SELECT tconst, averageRating, numVotes\n    FROM dbo.ratings\n    WHERE averageRating > 4.0\n),\n--break list by popularity into n-tile\nFilteredPopularity AS (\n    Select\n        imdb_id,\n        popularity,\n        genres,\n        overview,\n        ProductionCompanies,\n        NTILE(1) OVER (ORDER BY popularity DESC) AS popularity_percentile \n    from dbo.meta\n),\nFilteredBasics AS (\n    SELECT tconst, primaryTitle, startYear, runtimeMinutes\n    FROM dbo.basics\n    WHERE startYear >= 2010\n),\nBudget AS (\n    SELECT \n        imdb_id,\n        budget,\n        (revenue - budget) AS profit,\n    FROM dbo.meta\n)\nSELECT DISTINCT\n    cast.tconst, -- movie number unique id\n    base.primaryTitle, --movie name\n    cast.category,\n    rates.averageRating, -- ratings\n    nam.primaryName AS actor_name,\n    budget.budget,\n    budget.profit,\n    pop.popularity,\n    pop.genres,\n    pop.ProductionCompanies,\n    pop.overview\n\nFROM dbo.principals AS cast\nJOIN FilteredBasics AS base ON base.tconst = cast.tconst\nJOIN FilteredRatings AS rates ON rates.tconst = cast.tconst\nJOIN budget on budget.imdb_id = cast.tconst\nJOIN dbo.name AS nam ON nam.nconst = cast.nconst\nJOIN FilteredPopularity AS pop ON pop.imdb_id = cast.tconst\nWHERE cast.category IN ('actor', 'actress')\n    AND pop.popularity_percentile = 1\nORDER BY pop.popularity DESC;\n]\n(Background on this error at: https://sqlalche.me/e/20/f405)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mProgrammingError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\jeffd\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sqlalchemy\\engine\\base.py\u001b[0m in \u001b[0;36m_exec_single_context\u001b[1;34m(self, dialect, context, statement, parameters)\u001b[0m\n\u001b[0;32m   1966\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mevt_handled\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1967\u001b[1;33m                     self.dialect.do_execute(\n\u001b[0m\u001b[0;32m   1968\u001b[0m                         \u001b[0mcursor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr_statement\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0meffective_parameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\jeffd\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sqlalchemy\\engine\\default.py\u001b[0m in \u001b[0;36mdo_execute\u001b[1;34m(self, cursor, statement, parameters, context)\u001b[0m\n\u001b[0;32m    940\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mdo_execute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcursor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstatement\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 941\u001b[1;33m         \u001b[0mcursor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstatement\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    942\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mProgrammingError\u001b[0m: ('42000', \"[42000] [Microsoft][ODBC Driver 17 for SQL Server][SQL Server]Incorrect syntax near the keyword 'FROM'. (156) (SQLExecDirectW)\")",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mProgrammingError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_11756\\135500585.py\u001b[0m in \u001b[0;36m<cell line: 18>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconn_string\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;31m# Execute the query and load the data into a pandas DataFrame\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m \u001b[0mcte_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_sql\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcte_mega_string\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconn_string\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;31m# Display the first few rows of the dataframe\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\jeffd\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\io\\sql.py\u001b[0m in \u001b[0;36mread_sql\u001b[1;34m(sql, con, index_col, coerce_float, params, parse_dates, columns, chunksize, dtype_backend, dtype)\u001b[0m\n\u001b[0;32m    732\u001b[0m             )\n\u001b[0;32m    733\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 734\u001b[1;33m             return pandas_sql.read_query(\n\u001b[0m\u001b[0;32m    735\u001b[0m                 \u001b[0msql\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    736\u001b[0m                 \u001b[0mindex_col\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mindex_col\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\jeffd\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\io\\sql.py\u001b[0m in \u001b[0;36mread_query\u001b[1;34m(self, sql, index_col, coerce_float, parse_dates, params, chunksize, dtype, dtype_backend)\u001b[0m\n\u001b[0;32m   1834\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1835\u001b[0m         \"\"\"\n\u001b[1;32m-> 1836\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msql\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1837\u001b[0m         \u001b[0mcolumns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1838\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\jeffd\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\io\\sql.py\u001b[0m in \u001b[0;36mexecute\u001b[1;34m(self, sql, params)\u001b[0m\n\u001b[0;32m   1657\u001b[0m         \u001b[0margs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mparams\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1658\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msql\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1659\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcon\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexec_driver_sql\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msql\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1660\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcon\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msql\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1661\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\jeffd\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sqlalchemy\\engine\\base.py\u001b[0m in \u001b[0;36mexec_driver_sql\u001b[1;34m(self, statement, parameters, execution_options)\u001b[0m\n\u001b[0;32m   1777\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1778\u001b[0m         \u001b[0mdialect\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdialect\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1779\u001b[1;33m         ret = self._execute_context(\n\u001b[0m\u001b[0;32m   1780\u001b[0m             \u001b[0mdialect\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1781\u001b[0m             \u001b[0mdialect\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecution_ctx_cls\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_init_statement\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\jeffd\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sqlalchemy\\engine\\base.py\u001b[0m in \u001b[0;36m_execute_context\u001b[1;34m(self, dialect, constructor, statement, parameters, execution_options, *args, **kw)\u001b[0m\n\u001b[0;32m   1844\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_exec_insertmany_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdialect\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1845\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1846\u001b[1;33m             return self._exec_single_context(\n\u001b[0m\u001b[0;32m   1847\u001b[0m                 \u001b[0mdialect\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstatement\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1848\u001b[0m             )\n",
      "\u001b[1;32mc:\\Users\\jeffd\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sqlalchemy\\engine\\base.py\u001b[0m in \u001b[0;36m_exec_single_context\u001b[1;34m(self, dialect, context, statement, parameters)\u001b[0m\n\u001b[0;32m   1984\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1985\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1986\u001b[1;33m             self._handle_dbapi_exception(\n\u001b[0m\u001b[0;32m   1987\u001b[0m                 \u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr_statement\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0meffective_parameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcursor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1988\u001b[0m             )\n",
      "\u001b[1;32mc:\\Users\\jeffd\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sqlalchemy\\engine\\base.py\u001b[0m in \u001b[0;36m_handle_dbapi_exception\u001b[1;34m(self, e, statement, parameters, cursor, context, is_sub_exec)\u001b[0m\n\u001b[0;32m   2353\u001b[0m             \u001b[1;32melif\u001b[0m \u001b[0mshould_wrap\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2354\u001b[0m                 \u001b[1;32massert\u001b[0m \u001b[0msqlalchemy_exception\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2355\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0msqlalchemy_exception\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2356\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2357\u001b[0m                 \u001b[1;32massert\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\jeffd\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sqlalchemy\\engine\\base.py\u001b[0m in \u001b[0;36m_exec_single_context\u001b[1;34m(self, dialect, context, statement, parameters)\u001b[0m\n\u001b[0;32m   1965\u001b[0m                             \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1966\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mevt_handled\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1967\u001b[1;33m                     self.dialect.do_execute(\n\u001b[0m\u001b[0;32m   1968\u001b[0m                         \u001b[0mcursor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr_statement\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0meffective_parameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1969\u001b[0m                     )\n",
      "\u001b[1;32mc:\\Users\\jeffd\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sqlalchemy\\engine\\default.py\u001b[0m in \u001b[0;36mdo_execute\u001b[1;34m(self, cursor, statement, parameters, context)\u001b[0m\n\u001b[0;32m    939\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    940\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mdo_execute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcursor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstatement\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 941\u001b[1;33m         \u001b[0mcursor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstatement\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    942\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    943\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mdo_execute_no_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcursor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstatement\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mProgrammingError\u001b[0m: (pyodbc.ProgrammingError) ('42000', \"[42000] [Microsoft][ODBC Driver 17 for SQL Server][SQL Server]Incorrect syntax near the keyword 'FROM'. (156) (SQLExecDirectW)\")\n[SQL: \n\nWITH FilteredRatings AS (\n    SELECT tconst, averageRating, numVotes\n    FROM dbo.ratings\n    WHERE averageRating > 4.0\n),\n--break list by popularity into n-tile\nFilteredPopularity AS (\n    Select\n        imdb_id,\n        popularity,\n        genres,\n        overview,\n        ProductionCompanies,\n        NTILE(1) OVER (ORDER BY popularity DESC) AS popularity_percentile \n    from dbo.meta\n),\nFilteredBasics AS (\n    SELECT tconst, primaryTitle, startYear, runtimeMinutes\n    FROM dbo.basics\n    WHERE startYear >= 2010\n),\nBudget AS (\n    SELECT \n        imdb_id,\n        budget,\n        (revenue - budget) AS profit,\n    FROM dbo.meta\n)\nSELECT DISTINCT\n    cast.tconst, -- movie number unique id\n    base.primaryTitle, --movie name\n    cast.category,\n    rates.averageRating, -- ratings\n    nam.primaryName AS actor_name,\n    budget.budget,\n    budget.profit,\n    pop.popularity,\n    pop.genres,\n    pop.ProductionCompanies,\n    pop.overview\n\nFROM dbo.principals AS cast\nJOIN FilteredBasics AS base ON base.tconst = cast.tconst\nJOIN FilteredRatings AS rates ON rates.tconst = cast.tconst\nJOIN budget on budget.imdb_id = cast.tconst\nJOIN dbo.name AS nam ON nam.nconst = cast.nconst\nJOIN FilteredPopularity AS pop ON pop.imdb_id = cast.tconst\nWHERE cast.category IN ('actor', 'actress')\n    AND pop.popularity_percentile = 1\nORDER BY pop.popularity DESC;\n]\n(Background on this error at: https://sqlalche.me/e/20/f405)"
     ]
    }
   ],
   "source": [
    "import pyodbc\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "# connection details\n",
    "server = 'sourcetoshare.database.windows.net'\n",
    "database = 'imdb'\n",
    "username = 'jeffrey'\n",
    "password = 'JAw1BcMunBB7JGgKoWDNRwnUvNxDvW5yUClzwlomuIY8='\n",
    "driver = 'ODBC Driver 17 for SQL Server'\n",
    "\n",
    "\n",
    "# Create the connection string in SQLAlchemy format\n",
    "conn_string = f'mssql+pyodbc://{username}:{password}@{server}/{database}?driver={driver.replace(\" \", \"+\")}'\n",
    "\n",
    "# Create the SQLAlchemy engine\n",
    "engine = create_engine(conn_string)\n",
    "# Execute the query and load the data into a pandas DataFrame\n",
    "cte_df = pd.read_sql(cte_mega_string, conn_string)\n",
    "\n",
    "# Display the first few rows of the dataframe\n",
    "print(cte_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first we need to clean up the data\n",
    "# 1. remove empties\n",
    "cte_df = cte_df.dropna()\n",
    "# 2. remove entries with budgets of zero\n",
    "cte_df = cte_df[cte_df['budget'] != 0]\n",
    "#Creates a new binary column for each unique actor name. \n",
    "dummies_df = pd.get_dummies(cte_df, columns=['actor_name'])\n",
    "dummies_df.head(n=5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# We'll start easy by just using the profit and popularity columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation = dummies_df[['profit', 'popularity']].corr()\n",
    "print(correlation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now we'll use all the actor columns and the popularity column, since we're interested in the relationship between the actors and the popularity of the movie\n",
    "# We'll select all columns that start with 'actor_'\n",
    "# since there are a ton of names we'll use a loop to create a bunch of columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "selected_columns = ['popularity'] + [col for col in dummies_df.columns if col.startswith('actor_')]\n",
    "print(selected_columns[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we'll use all the actor columns and the popularity column, since we're interested in the relationship between the actors and the popularity of the movie\n",
    "# We'll select all columns that start with 'actor_'\n",
    "#since there are a ton of names we'll use a loop to create a bunch of columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new dataframe with only the selected columns\n",
    "new_df = dummies_df[selected_columns]\n",
    "\n",
    "# Calculate the correlation matrix\n",
    "pop_matrix = new_df.corr()\n",
    "\n",
    "# remove the 100 correlation with itself\n",
    "pop_matrix = pop_matrix.drop('popularity')\n",
    "\n",
    "# Remove the 'actor_' prefix from the index\n",
    "pop_matrix.index = pop_matrix.index.str.replace('actor_name_', '')\n",
    "\n",
    "# Display the correlation matrix\n",
    "pop_matrix= pop_matrix['popularity'].sort_values(ascending=False)\n",
    "\n",
    "print(pop_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Correlation results for popularity and actors\n",
    "# Those are not high correlations values. The presence of any actor does not seem to have a significant impact on the popularity of the movie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we'll use all the actor columns and the  column, since we're interested in the relationship between the actors and the profit of the movie\n",
    "selected_columns = ['profit'] + [col for col in dummies_df.columns if col.startswith('actor_')]\n",
    "new_df = dummies_df[selected_columns]\n",
    "profit_matrix = new_df.corr()\n",
    "profit_matrix = profit_matrix.drop('profit')\n",
    "profit_matrix = profit_matrix['profit'].sort_values(ascending=False)\n",
    "profit_matrix.index = profit_matrix.index.str.replace('actor_name_', '')\n",
    "print(profit_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Correlation result for profit and actors:\n",
    "# Those are not high correlations values. The presence of any actor does not seem to have a significant impact on the profit of the movie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "# Calculate the correlation matrixa Keep only the top 10 and bottom 10 correlations\n",
    "top_10 = pop_matrix.head(10)\n",
    "bottom_10 = pop_matrix.tail(10)\n",
    "top_bottom_20 = pd.concat([top_10, bottom_10])\n",
    "\n",
    "# Display the modified correlation series\n",
    "# Plot the correlations\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.barplot(x=top_bottom_20.values, y=top_bottom_20.index)\n",
    "plt.xlabel('Correlation with Popularity')\n",
    "plt.ylabel('Main Actor/Actress')\n",
    "plt.title('Correlation of Actor Presence with Movie Popularity')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Calculate the correlation  Keep only the top 10 and bottom 10 correlations\n",
    "top_10 = profit_matrix.head(10)\n",
    "bottom_10 = profit_matrix.tail(10)\n",
    "top_bottom_20 = pd.concat([top_10, bottom_10])\n",
    "\n",
    "# Display the modified correlation series\n",
    "# Plot the correlations\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.barplot(x=top_bottom_20.values, y=top_bottom_20.index)\n",
    "plt.xlabel('Correlation with Profit')\n",
    "plt.ylabel('Main Actor/Actress')\n",
    "plt.title('Correlation of Actor Presence with Movie Profit')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # I found this odd. Anyone see something I am doing wrong? I will do a random forrest now to see which factor contributes the most to popularity and profit. That will also to rank them. I thought for sure this star-power would matter more than this, but perhaps when I compare it to the other variables which may influence popularity or profit, star-power may yet be at the top.\n",
    " # I realized after talking with Derrick that I can't form a correlation with a list of names even if I matrix them. So this isn't correlating what I think it is. It isn't doing anything meaningful. I feel dumb... moving on.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# We assign a target for the random forest model:\n",
    "tget_column = 'profit'\n",
    "\n",
    "# Create a new data frame suitable for the arrandom forest model\n",
    "# shallow copy: dataframe copy() method, to make sure we don't alter the original data\n",
    "rand_forrest_df = cte_df.copy()\n",
    "\n",
    "# try to drop columns which are not useful especially if they are strings\n",
    "for col in rand_forrest_df.columns: #iterate through all columns\n",
    "    if rand_forrest_df[col].dtype == 'object': # if the column is a string\n",
    "\n",
    "        # then drop the column if it is not actor name genres or production companies\n",
    "        if col not in ['actor_name', 'genres', 'ProductionCompanies']: \n",
    "            rand_forrest_df.drop(columns=[col], inplace=True)\n",
    "rand_forrest_df.drop(columns=['profit_ratio'], inplace=True) # drop profit ratio as it is a derived column\n",
    "print(' ---   This is what the column headers it looks like now:   \\n')\n",
    "print(rand_forrest_df.columns)\n",
    "print('\\n')\n",
    "print(' ---   This is what it looks like now:\\n')\n",
    "print(rand_forrest_df.head())\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Separate features and target (profit)\n",
    "\n",
    "features = rand_forrest_df.drop(columns=[target_column])\n",
    "features = features.drop(columns=['popularity'])\n",
    "features = features.drop(columns=['budget']) #drop budget since this is presumably fixed\n",
    "features = features.drop(columns=['averageRating']) #drop average rating since we can't control this \n",
    "target = rand_forrest_df[target_column]\n",
    "\n",
    "# One-hot encode the categorical features (actor names, genres, production companies...)\n",
    "\n",
    "for column in features.select_dtypes(include=['object']).columns:\n",
    "    # Encode, append in place\n",
    "    features = pd.concat([features, pd.get_dummies(features[column])], axis=1) \n",
    "    features.drop(column, axis=1, inplace=True) #drop the original column\n",
    "\n",
    "print(' ---   This is the new size of our matrix (as in table):   \\n')\n",
    "print(features.size)\n",
    "print('\\n')\n",
    "print(' ---   This is the columns:   \\n')\n",
    "print(' ---   \\n see it is huge: ' + str(features.columns.size) + ' columns \\n')\n",
    "print(features.columns)\n",
    "print('\\n')\n",
    "print(' ---   This is what the data looks like now:\\n')\n",
    "print(features.head())\n",
    "print('\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Split into training and testing data\n",
    "# Testing on 30% of the data\n",
    "x_train, x_test, y_train, y_test = train_test_split(features, target, test_size=0.3, random_state=42)\n",
    "\n",
    "# Initialize the random forest model\n",
    "# n_estimators is the number of trees in the forest\n",
    "# random_state is the seed used by the random number generator\n",
    "rand_for = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "rand_for.fit(x_train, y_train)\n",
    "\n",
    "# Predict the profit on the test seta\n",
    "y_predict = rand_for.predict(x_test)\n",
    "\n",
    "# Calculate the mean squared error\n",
    "mse = np.mean((y_predict - y_test) ** 2)\n",
    "print(f\"Mean Squared Error (MSE): {mse}\")\n",
    "\n",
    "# report the accuracy of the model\n",
    "r2_score = rand_for.score(x_test, y_test)\n",
    "print(f\"R² (Model Accuracy): {r2_score}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's get a list of the most important features\n",
    "# And get a visual representation of the importance of each feature\n",
    "# There are way too many to display all of them, so we'll just display the top 10\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Get the feature importances, and the feature names\n",
    "features_importance = rand_for.feature_importances_\n",
    "feature_names = features.columns\n",
    "\n",
    "# Create a dataframe with the feature importances\n",
    "feature_df = pd.DataFrame({\n",
    "    'Feature': feature_names,\n",
    "    'Importance': features_importance\n",
    "})\n",
    "feature_df = feature_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "top_10_features = feature_df.head(50)\n",
    "\n",
    "# plotting the feature importances\n",
    "plt.figure(figsize=(13, 14))\n",
    "plt.barh(top_10_features['Feature'], top_10_features['Importance'], color='skyblue')\n",
    "# Add labels\n",
    "plt.title('Feature Importance')\n",
    "plt.xticks(np.arange(0, 0.2, 0.02))\n",
    "plt.xlabel('Importance')\n",
    "plt.ylabel('Feature')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The plot generated by the provided code is a horizontal bar plot that visualizes the importance of the top 10 features in your trained RandomForestRegressor model.  Feature importance is a measure of how much each feature contributes to the model's predictions. Higher importance values indicate that the feature has a greater impact on the model's output.\n",
    "\n",
    "\n",
    "# Not suprisingly the budget and popularity and things that are clearly related to profit are most predictive. But since we cannot control those things we can draw a conclusion that the most predictive and controllable thing is the production company, namely a big budget one like Warner Bros, Hedya Films, whoever they are.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"\"\"\n",
    " Let's try a different approach. \n",
    " The problem is that we have tried to individualize the importance of the actors \n",
    " This isn't going to work since there are so many different actors that any one actor's \n",
    " importance is going to be very low. What we really need is a way to compute the importance that \"ACTORS\" catagories matter.\n",
    " New plan: We are going to try to predict the profit of a movie based on the actors in the movie as a whole.\n",
    " how? we are going to create a new column that is the sum of all the actors in the movie individually,\n",
    " then j\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's examine the importances of actors\n",
    "# let's get the feature importances, and the feature names\n",
    "\n",
    "#print(rand_forrest_df.columns)\n",
    "f_importance = rand_for.feature_importances_\n",
    "f_names = features.columns\n",
    "importance_df = pd.DataFrame({'Feature' : f_names, 'Importances' : f_importance})\n",
    "total_importance = 0\n",
    "actor_importance = 0\n",
    "production_importance = 0\n",
    "genre_importance = 0\n",
    "\n",
    "print(rand_forrest_df.columns)\n",
    "\n",
    "print(f'the features array contains {f_names.size} entries')\n",
    "for name in f_names:\n",
    "    if name in rand_forrest_df['actor_name'].values:\n",
    "        actor_importance += importance_df[importance_df['Feature'] == name]['Importances'].values[0]\n",
    "        print(f\"{name} importance is {actor_importance}\")\n",
    "    if name in rand_forrest_df['ProductionCompanies'].values:\n",
    "        production_importance += importance_df[importance_df['Feature'] == name]['Importances'].values[0]\n",
    "    if name in rand_forrest_df['genres'].values:\n",
    "        genre_importance += importance_df[importance_df['Feature'] == name]['Importances'].values[0]\n",
    "    \n",
    "\n",
    "print(f\"Actor importance is {actor_importance}\")\n",
    "print(f\"Production importance is {production_importance}\")\n",
    "print(f\"Genre importance is {genre_importance}\")\n",
    "print(f\"Total importance is {actor_importance + production_importance + genre_importance}\")\n",
    "\n",
    "# lets make a pie chart\n",
    "plt.figure(figsize=(10, 10))\n",
    "labels = ['Actors', 'Production Companies', 'Genres']\n",
    "sizes = [actor_importance, production_importance, genre_importance]\n",
    "plt.pie(sizes, labels=labels, autopct='%1.1f%%', startangle=90)\n",
    "plt.axis('equal')\n",
    "plt.title('Feature Importance') \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PART II\n",
    "\n",
    "# Well, that was fun. But we still haven't compared the value of actors versus writers, directors, and the like. The SQL query will be different enough here to warrant a new SQL query.\n",
    "#\n",
    "# So let's get a new search, one that returns the other people who make movies possible and see what we get. We will also take the max amount of data from the data base.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This one will take a bit of time to run...\n",
    "# I will have to save this to a file and run it locally hopefully\n",
    "# That will speed things up. \n",
    "import pandas as pd\n",
    "CTE_all_emplyees = \"\"\"\n",
    "WITH FilteredRatings AS (\n",
    "    SELECT \n",
    "        tconst, \n",
    "        averageRating,\n",
    "        numVotes\n",
    "    FROM dbo.ratings\n",
    "    --WHERE averageRating > 8.0\n",
    "),\n",
    "FilteredPopularity AS (\n",
    "    Select\n",
    "        imdb_id,\n",
    "        popularity,\n",
    "        ProductionCompanies\n",
    "    from dbo.meta\n",
    "),\n",
    "FilteredBasics AS (\n",
    "    SELECT tconst,\n",
    "    primaryTitle,\n",
    "    startYear,\n",
    "    runtimeMinutes\n",
    "    FROM dbo.basics\n",
    "   -- WHERE startYear > 2000\n",
    "),\n",
    "Budget AS (\n",
    "    SELECT \n",
    "        imdb_id,\n",
    "        (revenue - budget) / budget AS profit_ratio\n",
    "    FROM dbo.meta\n",
    "    Where budget >0\n",
    ")\n",
    "SELECT DISTINCT\n",
    "    cast.tconst, -- movie number unique id\n",
    "    base.primaryTitle, --movie name\n",
    "    cast.category,\n",
    "    rates.averageRating, -- ratings\n",
    "    nam.primaryName AS employee,\n",
    "    base.runtimeMinutes,\n",
    "    pop.ProductionCompanies,\n",
    "    budget.profit_ratio\n",
    "\n",
    "FROM dbo.principals AS cast\n",
    "JOIN FilteredBasics AS base ON base.tconst = cast.tconst\n",
    "JOIN FilteredRatings AS rates ON rates.tconst = cast.tconst\n",
    "JOIN budget on budget.imdb_id = cast.tconst\n",
    "JOIN dbo.name AS nam ON nam.nconst = cast.nconst\n",
    "JOIN FilteredPopularity AS pop ON pop.imdb_id = cast.tconst\n",
    "\"\"\"\n",
    "# check if the file already exists\n",
    "# if not Execute the query and load into a pandas DataFrame\n",
    "import os\n",
    "if os.path.exists('Movies all_employees_BIG.csv'):\n",
    "    forrest_df = pd.read_csv('Movies all_employees_BIG.csv')\n",
    "else:\n",
    "    forrest_df = pd.read_sql(CTE_all_emplyees, conn_string)\n",
    "    # Display the first few rows of the dataframe\n",
    "    print(forrest_df.head())\n",
    "    forrest_df = forrest_df.dropna()\n",
    "    #save to filek\n",
    "    forrest_df.to_csv('Movies all_employees_BIG.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      tconst        primaryTitle category  averageRating            employee  \\\n",
      "0  tt0000417  A Trip to the Moon    actor            8.0             Brunnet   \n",
      "1  tt0000417  A Trip to the Moon    actor            8.0           Delpierre   \n",
      "2  tt0000417  A Trip to the Moon    actor            8.0             Farjaux   \n",
      "3  tt0000417  A Trip to the Moon    actor            8.0  François Lallement   \n",
      "4  tt0000417  A Trip to the Moon    actor            8.0      Georges Méliès   \n",
      "\n",
      "   runtimeMinutes ProductionCompanies  profit_ratio  \n",
      "0              13           Star-Film            -1  \n",
      "1              13           Star-Film            -1  \n",
      "2              13           Star-Film            -1  \n",
      "3              13           Star-Film            -1  \n",
      "4              13           Star-Film            -1  \n"
     ]
    }
   ],
   "source": [
    "print(forrest_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94626\n",
      "Columns to look at: Index(['tconst', 'primaryTitle', 'category', 'averageRating', 'employee',\n",
      "       'runtimeMinutes', 'ProductionCompanies', 'profit_ratio'],\n",
      "      dtype='object')\n",
      "unique employees: 39855\n",
      "unique categories: 13\n",
      "All unique categories: ['actor' 'actress' 'composer' 'producer' 'cinematographer' 'director'\n",
      " 'writer' 'production_designer' 'editor' 'self' 'archive_sound'\n",
      " 'casting_director' 'archive_footage']\n"
     ]
    }
   ],
   "source": [
    "print(forrest_df.index.size)\n",
    "print(f'Columns to look at: {forrest_df.columns}')\n",
    "print(f'unique employees: {forrest_df[\"employee\"].nunique()}')\n",
    "print(f'unique categories: {forrest_df[\"category\"].nunique()}')\n",
    "print(f'All unique categories: {forrest_df[\"category\"].unique()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We assign a target for the random forest model:\n",
    "# and remove the columns that are not useful for the model\n",
    "target = 'profit_ratio'\n",
    "forrest_df = forrest_df.drop(columns=['averageRating']) #drop average rating since we can't control this \n",
    "forrest_df = forrest_df.drop(columns=['tconst']) #drop tconst, not generalizable\n",
    "forrest_df = forrest_df.drop(columns=['primaryTitle']) #drop title, not generalizable\n",
    "\n",
    "# Separate features and target (profit)\n",
    "features_df = forrest_df.drop(columns=[target])\n",
    "target_df = forrest_df[target]\n",
    "\n",
    "print(features_df.select_dtypes(include=['object']).columns)\n",
    "# One-hot encode the categorical features (actor names, genres, production companies...)\n",
    "for column in features_df.select_dtypes(include=['object']).columns:\n",
    "    # Encode, append in place\n",
    "    features_df = pd.concat([features_df, pd.get_dummies(features_df[column])], axis=1) \n",
    "    features_df.drop(column, axis=1, inplace=True) #drop the original column\n",
    "\n",
    "# make sure the target and features have the same rows\n",
    "assert features_df.index.size == target_df.index.size, \"mismatched rows\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# this is a massive data set time to bring out the big guns\n",
    "# We need GPU power now\n",
    "# I summon nvidia cuda coreeeees!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import cuml\n",
    "#from cuml.ensemble import RandomForestRegressor as cuRF\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from cuml.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestRegressor \n",
    "# Testing on 30% of the data. Split into training and testing data\n",
    "x_train, x_test, y_train, y_test = train_test_split(features_df, target_df, test_size=0.3, random_state=42)\n",
    "\n",
    "# Initialize model, n_estimators = number trees, random_state is the seed\n",
    "#model = RandomForestRegressor(n_estimators=300, random_state=42)\n",
    "model = cuRF(n_estimators=300, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "# Predict the profit on the test seta\n",
    "prediction = model.predict(x_test)\n",
    "\n",
    "# Calculate the mean squared error\n",
    "mse = np.mean(prediction - y_test) ** 2\n",
    "print(f\"Mean Squared Error (MSE): {mse}\")\n",
    "\n",
    "# report the accuracy of the model\n",
    "\n",
    "r2_score = model.score(x_test, y_test)\n",
    "print(f\"R² (Model Accuracy): {r2_score}\")\n",
    "\n",
    "# print the confusion matrix # print the accuracy score\n",
    "\n",
    "conf_matrix = confusion_matrix(y_test, prediction)\n",
    "print(f\"Confusion Matrix: {conf_matrix}\")\n",
    "acc_score = accuracy_score(y_test, y_predict)\n",
    "print(f\"Accuracy: {acc_score}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
